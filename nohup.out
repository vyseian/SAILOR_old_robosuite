Gym has been unmaintained since 2022 and does not support NumPy 2.0 amongst other critical functionality.
Please upgrade to Gymnasium, the maintained drop-in replacement of Gym, or contact the authors of your software and request that they upgrade.
Users of this version of Gym should be able to simply replace 'import gym' with 'import gymnasium as gym' in the vast majority of cases.
See the migration guide at https://gymnasium.farama.org/introduction/migration_guide/ for additional information.
[robosuite WARNING] No private macro file found! (macros.py:53)
[robosuite WARNING] It is recommended to use a private macro file (macros.py:54)
[robosuite WARNING] To setup, run: python /home/vyseian/miniconda3/envs/robomimic_env/lib/python3.10/site-packages/robosuite/scripts/setup_macros.py (macros.py:55)
Logdir scratch_dir/logs/robomimic__square/None_demos299/seed0
---------------------
Task: robomimic__square
Logging to: scratch_dir/logs/robomimic__square/None_demos299/seed0
Time Limit: 500 | Max Env Steps: 756756
---------------------
ROBOMIMIC WARNING(
    No private macro file found!
    It is recommended to use a private macro file
    To setup, run: python /home/vyseian/miniconda3/envs/robomimic_env/lib/python3.10/site-packages/robomimic/scripts/setup_macros.py
)
Initizalizing norm_dict with ob_dim=9 and ac_dim=7
Loaded 299 training episodes
Loaded 1 validation episodes
Min expert demo length: 123
Max expert demo length: 1051
Avg expert demo length: 268.8026755852843
Enviroment State Dim: 9, Action Dim: 7
Initialized robomimic env with action repeat: 1, time limit: 500
Initialized robomimic env with action repeat: 1, time limit: 500
Initialized robomimic env with action repeat: 1, time limit: 500
Initialized robomimic env with action repeat: 1, time limit: 500
Initialized robomimic env with action repeat: 1, time limit: 500
Initialized robomimic env with action repeat: 1, time limit: 500
Initialized robomimic env with action repeat: 1, time limit: 500
Initialized robomimic env with action repeat: 1, time limit: 500
Initialized robomimic env with action repeat: 1, time limit: 500
Initialized robomimic env with action repeat: 1, time limit: 500
Initialized robomimic env with action repeat: 1, time limit: 500
Initialized robomimic env with action repeat: 1, time limit: 500
Initialized robomimic env with action repeat: 1, time limit: 500
Initialized robomimic env with action repeat: 1, time limit: 500
Initialized robomimic env with action repeat: 1, time limit: 500
Initialized robomimic env with action repeat: 1, time limit: 500
Initialized robomimic env with action repeat: 1, time limit: 500
Initialized robomimic env with action repeat: 1, time limit: 500
Initialized robomimic env with action repeat: 1, time limit: 500
Initialized robomimic env with action repeat: 1, time limit: 500
Initialized robomimic env with action repeat: 1, time limit: 500
Initialized robomimic env with action repeat: 1, time limit: 500
Initialized robomimic env with action repeat: 1, time limit: 500
Initialized robomimic env with action repeat: 1, time limit: 500
Initialized robomimic env with action repeat: 1, time limit: 500
Initialized robomimic env with action repeat: 1, time limit: 500
Initialized robomimic env with action repeat: 1, time limit: 500
Initialized robomimic env with action repeat: 1, time limit: 500
Initialized robomimic env with action repeat: 1, time limit: 500
Initialized robomimic env with action repeat: 1, time limit: 500
Initialized robomimic env with action repeat: 1, time limit: 500
Initialized robomimic env with action repeat: 1, time limit: 500
Initialized robomimic env with action repeat: 1, time limit: 500
Initialized robomimic env with action repeat: 1, time limit: 500
Initialized robomimic env with action repeat: 1, time limit: 500
Initialized robomimic env with action repeat: 1, time limit: 500
Initialized robomimic env with action repeat: 1, time limit: 500
Initialized robomimic env with action repeat: 1, time limit: 500
Initialized robomimic env with action repeat: 1, time limit: 500
Initialized robomimic env with action repeat: 1, time limit: 500
Initialized robomimic env with action repeat: 1, time limit: 500
Initialized robomimic env with action repeat: 1, time limit: 500
Initialized robomimic env with action repeat: 1, time limit: 500
Initialized robomimic env with action repeat: 1, time limit: 500
Initialized robomimic env with action repeat: 1, time limit: 500
Initialized robomimic env with action repeat: 1, time limit: 500
Initialized robomimic env with action repeat: 1, time limit: 500
Initialized robomimic env with action repeat: 1, time limit: 500
Initialized robomimic env with action repeat: 1, time limit: 500
Initialized robomimic env with action repeat: 1, time limit: 500
Action Space: Box(-1.0, 1.0, (7,), float32). Low: [-1. -1. -1. -1. -1. -1. -1.]. High: [1. 1. 1. 1. 1. 1. 1.]

-----------------Begin training SAILOR --------------
Initializing SAILORTrainer with init_step: 0
DiffusionUnet + ResNet18 has 27272407 parameters
Scheduler Initialized:  <data4robotics.trainers.base.CosineAnnealingWarmupRestarts object at 0x71374f74f790>
Loading DP checkpoint from:  /home/vyseian/GitHub/SAILOR/scratch_dir/logs/robomimic__square/seed0_demos299/seed0/latest_base_policy.pt
Encoder CNN shapes: {'agentview_image': (64, 64, 3), 'robot0_eye_in_hand_image': (64, 64, 3)}
Encoder MLP shapes: {'state': (9,)}
Decoder CNN shapes: {'agentview_image': (64, 64, 3), 'robot0_eye_in_hand_image': (64, 64, 3)}
Decoder MLP shapes: {'state': (9,)}
Optimizer model_opt has 25034640 variables.
Optimizer discrim_opt has 1051137 variables.
Optimizer value_opt has 5255685 variables.
Compiling models
Loading MPPI World Model from: /home/vyseian/GitHub/SAILOR/scratch_dir/logs/robomimic__square/seed0_demos299/seed0/latest_residual_checkpoint.pt
Loaded dreamer checkpoint from /home/vyseian/GitHub/SAILOR/scratch_dir/logs/robomimic__square/seed0_demos299/seed0/latest_residual_checkpoint.pt

----------------- Running Large Scale Evaluation -----------------

Evaluating MPPI Policy
Initialized ResidualAgent with Base Policy + MPPI correction
Storing model weights params and loading EMA to model.
Evaluating Agent num_eval_runs: 1000, num_envs: 50, NUM_RUNS: 20
Seed: 0
Storing model weights params and loading EMA to model.
EVALUATING 50 ENVIRONMENTS on SEED 0
	Average Success Rate: 0.38
	Average Total Reward: -321.02519262799274
	Average Episode Length: 430.28
	Average Total Orig Reward: 109.63480737200727
Seed: 1
Storing model weights params and loading EMA to model.
EVALUATING 50 ENVIRONMENTS on SEED 1
	Average Success Rate: 0.38
	Average Total Reward: -318.3833182490239
	Average Episode Length: 436.82
	Average Total Orig Reward: 118.81668175097619
Seed: 2
Storing model weights params and loading EMA to model.
EVALUATING 50 ENVIRONMENTS on SEED 2
	Average Success Rate: 0.54
	Average Total Reward: -290.0446759937882
	Average Episode Length: 414.3
	Average Total Orig Reward: 124.79532400621184
Seed: 3
Storing model weights params and loading EMA to model.
EVALUATING 50 ENVIRONMENTS on SEED 3
	Average Success Rate: 0.52
	Average Total Reward: -302.42628358237306
	Average Episode Length: 413.62
	Average Total Orig Reward: 111.71371641762698
Seed: 4
Storing model weights params and loading EMA to model.
EVALUATING 50 ENVIRONMENTS on SEED 4
	Average Success Rate: 0.44
	Average Total Reward: -307.04335812839884
	Average Episode Length: 421.6
	Average Total Orig Reward: 114.99664187160106
Seed: 5
Storing model weights params and loading EMA to model.
EVALUATING 50 ENVIRONMENTS on SEED 5
	Average Success Rate: 0.52
	Average Total Reward: -303.7193549764888
	Average Episode Length: 419.5
	Average Total Orig Reward: 116.30064502351127
Seed: 6
Storing model weights params and loading EMA to model.
EVALUATING 50 ENVIRONMENTS on SEED 6
	Average Success Rate: 0.36
	Average Total Reward: -323.76359910161153
	Average Episode Length: 450.4
	Average Total Orig Reward: 126.99640089838853
Seed: 7
Storing model weights params and loading EMA to model.
EVALUATING 50 ENVIRONMENTS on SEED 7
	Average Success Rate: 0.4
	Average Total Reward: -328.1884569096494
	Average Episode Length: 440.26
	Average Total Orig Reward: 112.4715430903504
Seed: 8
Storing model weights params and loading EMA to model.
EVALUATING 50 ENVIRONMENTS on SEED 8
	Average Success Rate: 0.48
	Average Total Reward: -303.99527155334783
	Average Episode Length: 425.88
	Average Total Orig Reward: 122.36472844665215
Seed: 9
Storing model weights params and loading EMA to model.
EVALUATING 50 ENVIRONMENTS on SEED 9
	Average Success Rate: 0.54
	Average Total Reward: -309.9008870025086
	Average Episode Length: 420.5
	Average Total Orig Reward: 111.13911299749132
Seed: 10
Storing model weights params and loading EMA to model.
EVALUATING 50 ENVIRONMENTS on SEED 10
	Average Success Rate: 0.44
	Average Total Reward: -314.31835207290965
	Average Episode Length: 424.94
	Average Total Orig Reward: 111.06164792709043
Seed: 11
Storing model weights params and loading EMA to model.
EVALUATING 50 ENVIRONMENTS on SEED 11
	Average Success Rate: 0.42
	Average Total Reward: -315.3930912915412
	Average Episode Length: 433.28
	Average Total Orig Reward: 118.3069087084589
Seed: 12
Storing model weights params and loading EMA to model.
EVALUATING 50 ENVIRONMENTS on SEED 12
	Average Success Rate: 0.42
	Average Total Reward: -308.3025722861914
	Average Episode Length: 429.08
	Average Total Orig Reward: 121.19742771380871
Seed: 13
Storing model weights params and loading EMA to model.
EVALUATING 50 ENVIRONMENTS on SEED 13
	Average Success Rate: 0.42
	Average Total Reward: -310.5482797978355
	Average Episode Length: 432.18
	Average Total Orig Reward: 122.05172020216442
Seed: 14
Storing model weights params and loading EMA to model.
EVALUATING 50 ENVIRONMENTS on SEED 14
	Average Success Rate: 0.52
	Average Total Reward: -296.8264151678265
	Average Episode Length: 414.12
	Average Total Orig Reward: 117.8135848321736
Seed: 15
Storing model weights params and loading EMA to model.
EVALUATING 50 ENVIRONMENTS on SEED 15
	Average Success Rate: 0.46
	Average Total Reward: -316.60286789546944
	Average Episode Length: 416.82
	Average Total Orig Reward: 100.6771321045305
Seed: 16
Storing model weights params and loading EMA to model.
EVALUATING 50 ENVIRONMENTS on SEED 16
	Average Success Rate: 0.42
	Average Total Reward: -323.31960974124576
	Average Episode Length: 436.06
	Average Total Orig Reward: 113.16039025875438
Seed: 17
Storing model weights params and loading EMA to model.
EVALUATING 50 ENVIRONMENTS on SEED 17
	Average Success Rate: 0.4
	Average Total Reward: -297.00129992434734
	Average Episode Length: 417.96
	Average Total Orig Reward: 121.35870007565264
Seed: 18
Storing model weights params and loading EMA to model.
EVALUATING 50 ENVIRONMENTS on SEED 18
	Average Success Rate: 0.44
	Average Total Reward: -304.9205627339313
	Average Episode Length: 423.36
	Average Total Orig Reward: 118.87943726606876
Seed: 19
Storing model weights params and loading EMA to model.
EVALUATING 50 ENVIRONMENTS on SEED 19
	Average Success Rate: 0.52
	Average Total Reward: -285.71426778546606
	Average Episode Length: 397.54
	Average Total Orig Reward: 112.3457322145338
Average Success Rate: 0.45099999999999996
Average Total Average Reward: -309.07188584109736
Average Episode Length: 424.925
Average Total Average Orig Reward: 116.30411415890265
Time taken: 16701.160039901733
[Histogram], Key: residual_counts, Counts: [      0.       0.       0.       0.       0.    4533.   23699.  108531.
  446127. 1178556. 1170498.  438930.  103334.   21695.    4097.       0.
       0.       0.       0.       0.]
[Histogram], Key: base_counts, Counts: [ 220454.   32206.   15055.   11821.    9280.    9363.   18189.   56038.
  207795. 1306545. 1147357.  140922.   53265.   33351.   23151.   17455.
   13083.   10570.   12238.  161862.]
Finished evaluation of 1000 trajectories.
